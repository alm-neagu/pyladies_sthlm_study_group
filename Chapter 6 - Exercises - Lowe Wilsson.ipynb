{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISES: CHAPTER 6\n",
    "## Data Loading, Storage, and File Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 0: Generate a random CSV file and read it in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "0. Go to this site: https://mockaroo.com/\n",
    "1. Try playing around with picking different types of mock data if you want\n",
    "2. Make sure the 'Format' is set to CSV (should be the default).\n",
    "3. Scroll down a bit, click 'Download Data', and save to wherever you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0\n",
    "Read in the mocked data as a data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 0. Copy the file path to your file (if you don't know how to do this quickly, search for instructions for your operating system) \n",
    "# 1. Paste your file path to a Python script like this one, and run it.\n",
    "fpath = '/Users/lowe/Downloads/MOCK_DATA.csv'\n",
    "df = pd.read_csv(fpath)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Save the produced dataframe's contents to a new .csv file, using `;` as the field delimiter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('foobar.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Copy a HTML table from a webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "0. Go to this Wikipedia page: https://en.wikipedia.org/wiki/List_of_C-family_programming_languages\n",
    "1. Scroll down to the table of different programming languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Copy the header and the first five rows (down to the 'C++' row) from the web page's table into a data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "0. Highlight the header and the first five rows by simply using your mouse. \n",
    "1. Use Ctrl+C (Cmd+C) to copy the highlighted text to your clipboard. \n",
    "2. Go to your Jupyter notebook and run the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_clipboard()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Convert a Python list of dictionaries to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "Run the code snippet below to create a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [\n",
    "    {'name': 'Breonna', 'age': 26, 'profession': 'Nurse'},\n",
    "    {'name': 'Ada', 'age': 36, 'profession': 'Programmer', 'Interests': ['Poetry', 'Poetical Science']},\n",
    "    {'name': 'Charles', 'age': 79, 'profession': 'Programmer'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data in `people` to a string of JSON-formatted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "people_json = json.dumps(people)\n",
    "people_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Copy a HTML table from a webpage, again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Install (`pip install`/`conda install`) the packages `lxml`, `beautifulsoup4` and `html5lib`, if you don't already have them\n",
    "1. Go to https://c19.se/ , which has COVID-19 statistics for Sweden\n",
    "2. Scroll down to where you see a table of by-region statistics (actually two tables, since the summary statistics are in a HTML table element of their own)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert/import the by-region HTML table to a pandas dataframe and sort it by total number of cases (the 'Fall' column)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 0. Right click the webpage in your web browser and choose 'Save Page As...'\n",
    "# 1. Copy the file path to the downloaded .html file.\n",
    "# 2. Paste the file path into a code snippet like this one.\n",
    "fpath = '/Users/lowe/Desktop/C19.SE - Coronavirus i Sverige.html'\n",
    "# let pandas parse the html, creating a list of dataframes\n",
    "covid_frames = pd.read_html(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# check how many tables were found (/data frames were created)\n",
    "len(covid_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# take a look at the first dataframe\n",
    "covid_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# that's what we want, so make a copy that we can edit without\n",
    "# changing the original data (in case we want to start over later)\n",
    "covid_regions_df = covid_frames[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# check the data type of the 'Fall idag' (cases today) column\n",
    "covid_regions_df['Fall'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# the 'number of cases today' column isn't reliably interpreted as being of integer type\n",
    "# (so you might get `dtype('0')` above) which is a problem since we want to sort by numeric value.\n",
    "# in that case, you need to clean and convert the data using something like this code\n",
    "# snippet.\n",
    "\n",
    "# remove all whitespace, e. g. '2 830'->'2830'\n",
    "covid_regions_df['Fall'] = covid_regions_df['Fall'].str.replace(' ', '')\n",
    "# convert to integer type\n",
    "covid_regions_df['Fall'] = covid_regions_df['Fall'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# sort by number of cases today\n",
    "covid_regions_df.sort_values('Fall', inplace=True)\n",
    "covid_regions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Fetch JSON data from an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API stands for **Application Programming Interface**. It's a broad term that roughly describes *an interface, a set of commands, that can be used to make some piece of technology and/or software do things*. In the context of databases, an API means an interface that allows you to retrieve or manipulate the contents of a database. For a simple example, say you have a database about ice creams, which holds each ice cream's name and price. You could then let outside users connect to your database and tell it to send them a list of all the ice creams in your database, or to delete all the ice creams in the database. You could call these two commands \"GET ALL ICECREAM\" and \"DELETE ALL ICECREAM\". The users don't know how exactly your database actually executes the commands, only how to give them. That's an API consisting of a set of two instructions. Obviously it has its drawbacks, and API's in the wild usually offer more comprehensive and refined sets of commands, as we'll see.\n",
    "\n",
    "In this exercise we interact with the [Open Movie Database](https://www.omdbapi.com/). Its API is relatively beginner-friendly and has been stable for a long time, so it's easy to get started. To use it you need to get an *API key* (essentially a 'username' and 'password' in a single code). Luckily anyone can register for a key and all you need is an e-mail address. Go to [this page](https://www.omdbapi.com/apikey.aspx) to register, choosing the 'free' option.  Check your e-mail inbox for a message with your API key, then briefly read through the [Usage](https://www.omdbapi.com/#usage) and [Parameters](https://www.omdbapi.com/#parameters) sections. Finally, try a couple of [Examples](https://www.omdbapi.com/#examples).\n",
    "\n",
    "If you don't have it yet (if you have Anaconda you're good to go), `pip install` the **requests** package.\n",
    "\n",
    "*(note: fetching data about movies might not feel very 'data science-y', of course. the point here is simply to get a feel for how interacting with an API works, because this in itself can become quite complicated)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve data for all movies from 1951 with 'cat' in the title and put them in a pandas dataframe. (1951 is chosen simply because it makes for a very manageable dataset of a few, rather than hundreds of, movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "1. Use the web site's 'examples' form to do a search with 'Title' set to 'cat' and 'Year' set to '1951'. You'll see that the request URL looks like this: 'http://www.omdbapi.com/?t=cat&y=1951'. This is a URL ('Universal Resource Locator', very roughly an 'internet address') that applies the filters that we want. The most important parts are the parameters at the end, 't=cat&y=1951', basically meaning 'title must include cat, and year must be 1951'.\n",
    "2. Look at the single-record response shown below the search form to see how each movie's data are formatted. Each record is structured as a 'dictionary', like this:\n",
    "> {\"Title\":\"Cat Napping\",\"Year\":\"1951\",\"Rated\":\"Approved\",\"Released\":\"08 Dec 1951\",\"Runtime\":\"7 min\",\"Genre\":\"Animation, Short, Comedy, Family\",\"Director\":\"Joseph Barbera, William Hanna\",\"Writer\":\"N/A\",\"Actors\":\"N/A\",\"Plot\":\"Tom's getting ready to settle into the hammock, but Jerry has beat him to it and the battle begins.\",\"Language\":\"English\",\"Country\":\"USA\",\"Awards\":\"N/A\",\"Poster\":\"https://m.media-amazon.com/images/M/MV5BZTYwMGY0NGMtOTQzMy00YjVmLTk5YmEtZjZiNjRiM2VhNzVkXkEyXkFqcGdeQXVyNjMxODMyODU@._V1_SX300.jpg\",\"Ratings\":[{\"Source\":\"Internet Movie Database\",\"Value\":\"7.5/10\"}],\"Metascore\":\"N/A\",\"imdbRating\":\"7.5\",\"imdbVotes\":\"643\",\"imdbID\":\"tt0043387\",\"Type\":\"movie\",\"DVD\":\"N/A\",\"BoxOffice\":\"N/A\",\"Production\":\"N/A\",\"Website\":\"N/A\",\"Response\":\"True\"}\n",
    "\n",
    "This format is called a 'records' format by pandas, as can be seen in the [documentation for `read_json`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html)\n",
    "\n",
    "3. Note that the examples form uses the 't' parameter, which means that the response will only include a **single** movie. We however want **all** movies from 1951 that have 'cat' in their titles. If we look at the [Parameters](https://www.omdbapi.com/#parameters) section again we see that to do a proper search (that can return multiple movies) we need to use the 's' parameter instead of 't'.\n",
    "\n",
    "3. Based on the above, we know that we want to send a GET (this is the default in the 'requests' package) request to 'http://www.omdbapi.com'. The request should have the following parameters:\n",
    "\n",
    "* apikey: --API key sent in e-mail--\n",
    "* s: cat\n",
    "* y: 1951\n",
    "\n",
    "4. Use the following code, which makes use of the information you collected in the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the requests package and the JSON package\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# specify the address to the API site (the 'API endpoint')\n",
    "api_endpoint = 'http://www.omdbapi.com'\n",
    "# form a dictionary of request parameters\n",
    "url_parameters = {\n",
    "    'apikey': 'INSERTAPIKEYHERE',\n",
    "    's': 'cat',\n",
    "    'y': 1951\n",
    "}\n",
    "\n",
    "# use the `requests` package's `get` function to make a\n",
    "# GET ('retrieve data') request to the API endpoint, \n",
    "# including the request parameters.\n",
    "# this produces a Response object, which includes\n",
    "# a lot of information about the API's response\n",
    "requests_resp = requests.get(api_endpoint, url_parameters)\n",
    "type(requests_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# we are only interested in the data sent back by the API,\n",
    "# which are in the Response object's 'content' attribute\n",
    "raw_json = requests_resp.content\n",
    "# let's see how the actual search query response is formatted\n",
    "raw_json[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# the movie data are inside of a 'list' (array) linked to the 'Search' key.\n",
    "# this means that giving the data directly to pandas, only specifying\n",
    "# the 'records' format, won't work.\n",
    "# instead we can use Python's json package to convert from JSON\n",
    "# to a python dictionary, extract the data as a list, and hand it\n",
    "# off to pandas. \n",
    "\n",
    "# first, we use the json package's\n",
    "# `json.reads` (read string) function to \n",
    "# convert from JSON to dictionary\n",
    "data_dict = json.loads(raw_json)\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# we now extract the list of data\n",
    "data_ls = data_dict['Search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# finally we pass the list of data to pandas' DataFrame constructor\n",
    "movie_cat1951_df = pd.DataFrame(data_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# now all movies from 1951 with 'cat' in the title (that are in the\n",
    "# open movie database) are in the dataframe\n",
    "movie_cat1951_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out and compare the number of movies from 1951 with 'dog' in the title with the number of 1951 movies with 'cat' in the title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "url_parameters = {\n",
    "    'apikey': 'INSERTAPIKEYHERE',\n",
    "    's': 'dog', # NEW\n",
    "    'y': 1951\n",
    "}\n",
    "\n",
    "requests_resp = requests.get(api_endpoint, url_parameters)\n",
    "raw_json = requests_resp.content\n",
    "data_dict = json.loads(raw_json)\n",
    "data_ls = data_dict['Search']\n",
    "\n",
    "movie_dog1951_df = pd.DataFrame(data_ls) # NEW\n",
    "movie_dog1951_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# get the number of rows in each data frame to figure out the number of\n",
    "# movies in each category\n",
    "num_dog_movies = len(movie_dog1951_df)\n",
    "num_cat_movies = len(movie_cat1951_df)\n",
    "# compare the numbers to see what the correct conclusion is\n",
    "if num_dog_movies > num_cat_movies:\n",
    "    conclusion = \"there were more dog than cat movies\"\n",
    "elif num_dog_movies < num_cat_movies:\n",
    "    conclusion = \"there were more cat than dog movies\"\n",
    "else:\n",
    "    conclusion = \"there were as many cat as dog movies\"\n",
    "# print the results\n",
    "print(f\"There were \" + str(num_dog_movies) + \" dog movies and \" + str(num_cat_movies) + \" cat movies in 1951, meaning that \" + conclusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
